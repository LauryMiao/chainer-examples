{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer.dataset import concat_examples\n",
    "from chainer import initializers\n",
    "import numpy as np\n",
    "from chainer.utils import type_check\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(chainer.Chain):\n",
    "    def __init__(self, in_size, out_size):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.l1 = L.Linear(in_size, out_size)\n",
    "            \n",
    "    def __call__(self, x):\n",
    "        h = self.l1(x)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "learning_rate = 0.01\n",
    "training_epochs = 100\n",
    "display_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train, test = chainer.datasets.get_mnist(withlabel=True, ndim=1, scale=1.)\n",
    "reduced_train = chainer.iterators.SerialIterator(dataset=train, batch_size=5000, repeat=True, shuffle=True).next()\n",
    "reduced_test = chainer.iterators.SerialIterator(dataset=train, batch_size=500, repeat=True, shuffle=True).next()\n",
    "train_iter = chainer.iterators.SerialIterator(dataset=reduced_train, batch_size=100, repeat=True, shuffle=True)\n",
    "test_iter = chainer.iterators.SerialIterator(dataset=reduced_test, batch_size=100, repeat=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model & optimiser\n",
    "model = LogisticRegression(784, 10)\n",
    "optimiser = chainer.optimizers.SGD(lr=learning_rate)\n",
    "optimiser.setup(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_iter_state(iterator):\n",
    "    iterator.epoch = 0\n",
    "    iterator.current_position = 0\n",
    "    iterator.is_new_epoch = False\n",
    "    iterator._pushed_position = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=002 train_loss=1.97720 val_loss=1.90184 val_accuracy=0.51000\n",
      "epoch=003 train_loss=1.59115 val_loss=1.58910 val_accuracy=0.69200\n",
      "epoch=004 train_loss=1.37699 val_loss=1.37247 val_accuracy=0.72200\n",
      "epoch=005 train_loss=1.23446 val_loss=1.21922 val_accuracy=0.75400\n",
      "epoch=006 train_loss=1.10783 val_loss=1.10697 val_accuracy=0.78800\n",
      "epoch=007 train_loss=0.96216 val_loss=1.02269 val_accuracy=0.79400\n",
      "epoch=008 train_loss=0.97025 val_loss=0.95666 val_accuracy=0.80000\n",
      "epoch=009 train_loss=0.96979 val_loss=0.90328 val_accuracy=0.81400\n",
      "epoch=010 train_loss=0.77683 val_loss=0.86041 val_accuracy=0.82200\n",
      "epoch=011 train_loss=0.83561 val_loss=0.82285 val_accuracy=0.82400\n",
      "epoch=012 train_loss=0.77678 val_loss=0.79236 val_accuracy=0.82200\n",
      "epoch=013 train_loss=0.71521 val_loss=0.76631 val_accuracy=0.82000\n",
      "epoch=014 train_loss=0.73232 val_loss=0.74301 val_accuracy=0.82600\n",
      "epoch=015 train_loss=0.72577 val_loss=0.72308 val_accuracy=0.83000\n",
      "epoch=016 train_loss=0.67781 val_loss=0.70545 val_accuracy=0.82800\n",
      "epoch=017 train_loss=0.62827 val_loss=0.68931 val_accuracy=0.83400\n",
      "epoch=018 train_loss=0.69301 val_loss=0.67496 val_accuracy=0.83400\n",
      "epoch=019 train_loss=0.62558 val_loss=0.66195 val_accuracy=0.83800\n",
      "epoch=020 train_loss=0.57082 val_loss=0.65038 val_accuracy=0.83800\n",
      "epoch=021 train_loss=0.65834 val_loss=0.63956 val_accuracy=0.83800\n",
      "epoch=022 train_loss=0.49892 val_loss=0.62927 val_accuracy=0.84200\n",
      "epoch=023 train_loss=0.64777 val_loss=0.62038 val_accuracy=0.83800\n",
      "epoch=024 train_loss=0.59233 val_loss=0.61265 val_accuracy=0.84000\n",
      "epoch=025 train_loss=0.42651 val_loss=0.60446 val_accuracy=0.83600\n",
      "epoch=026 train_loss=0.62950 val_loss=0.59686 val_accuracy=0.83600\n",
      "epoch=027 train_loss=0.56048 val_loss=0.59068 val_accuracy=0.83800\n",
      "epoch=028 train_loss=0.65362 val_loss=0.58380 val_accuracy=0.83800\n",
      "epoch=029 train_loss=0.60817 val_loss=0.57811 val_accuracy=0.84000\n",
      "epoch=030 train_loss=0.51813 val_loss=0.57256 val_accuracy=0.84400\n",
      "epoch=031 train_loss=0.43328 val_loss=0.56748 val_accuracy=0.84600\n",
      "epoch=032 train_loss=0.55977 val_loss=0.56254 val_accuracy=0.84600\n",
      "epoch=033 train_loss=0.43306 val_loss=0.55752 val_accuracy=0.84600\n",
      "epoch=034 train_loss=0.42265 val_loss=0.55310 val_accuracy=0.84800\n",
      "epoch=035 train_loss=0.54869 val_loss=0.54857 val_accuracy=0.85000\n",
      "epoch=036 train_loss=0.54001 val_loss=0.54481 val_accuracy=0.85000\n",
      "epoch=037 train_loss=0.36553 val_loss=0.54076 val_accuracy=0.85000\n",
      "epoch=038 train_loss=0.42042 val_loss=0.53730 val_accuracy=0.85000\n",
      "epoch=039 train_loss=0.41103 val_loss=0.53414 val_accuracy=0.85000\n",
      "epoch=040 train_loss=0.39957 val_loss=0.53070 val_accuracy=0.85200\n",
      "epoch=041 train_loss=0.43201 val_loss=0.52697 val_accuracy=0.85200\n",
      "epoch=042 train_loss=0.39876 val_loss=0.52417 val_accuracy=0.85400\n",
      "epoch=043 train_loss=0.55654 val_loss=0.52118 val_accuracy=0.85600\n",
      "epoch=044 train_loss=0.45556 val_loss=0.51836 val_accuracy=0.85600\n",
      "epoch=045 train_loss=0.38794 val_loss=0.51568 val_accuracy=0.85600\n",
      "epoch=046 train_loss=0.52159 val_loss=0.51325 val_accuracy=0.85400\n",
      "epoch=047 train_loss=0.50576 val_loss=0.51079 val_accuracy=0.85600\n",
      "epoch=048 train_loss=0.49038 val_loss=0.50820 val_accuracy=0.85400\n",
      "epoch=049 train_loss=0.45098 val_loss=0.50587 val_accuracy=0.85400\n",
      "epoch=050 train_loss=0.42365 val_loss=0.50335 val_accuracy=0.85800\n",
      "epoch=051 train_loss=0.48505 val_loss=0.50136 val_accuracy=0.86000\n",
      "epoch=052 train_loss=0.38887 val_loss=0.49925 val_accuracy=0.86000\n",
      "epoch=053 train_loss=0.26756 val_loss=0.49742 val_accuracy=0.86000\n",
      "epoch=054 train_loss=0.50137 val_loss=0.49556 val_accuracy=0.86000\n",
      "epoch=055 train_loss=0.69184 val_loss=0.49347 val_accuracy=0.86000\n",
      "epoch=056 train_loss=0.55528 val_loss=0.49149 val_accuracy=0.86200\n",
      "epoch=057 train_loss=0.42065 val_loss=0.48971 val_accuracy=0.86400\n",
      "epoch=058 train_loss=0.41087 val_loss=0.48780 val_accuracy=0.86600\n",
      "epoch=059 train_loss=0.46684 val_loss=0.48652 val_accuracy=0.86400\n",
      "epoch=060 train_loss=0.41464 val_loss=0.48457 val_accuracy=0.86200\n",
      "epoch=061 train_loss=0.46543 val_loss=0.48296 val_accuracy=0.86400\n",
      "epoch=062 train_loss=0.29002 val_loss=0.48140 val_accuracy=0.86400\n",
      "epoch=063 train_loss=0.37365 val_loss=0.47974 val_accuracy=0.86400\n",
      "epoch=064 train_loss=0.49161 val_loss=0.47826 val_accuracy=0.86400\n",
      "epoch=065 train_loss=0.43488 val_loss=0.47664 val_accuracy=0.86400\n",
      "epoch=066 train_loss=0.34998 val_loss=0.47535 val_accuracy=0.86400\n",
      "epoch=067 train_loss=0.45725 val_loss=0.47394 val_accuracy=0.86400\n",
      "epoch=068 train_loss=0.41091 val_loss=0.47258 val_accuracy=0.86400\n",
      "epoch=069 train_loss=0.49269 val_loss=0.47129 val_accuracy=0.86600\n",
      "epoch=070 train_loss=0.43603 val_loss=0.47007 val_accuracy=0.86600\n",
      "epoch=071 train_loss=0.38529 val_loss=0.46871 val_accuracy=0.86400\n",
      "epoch=072 train_loss=0.42025 val_loss=0.46759 val_accuracy=0.86600\n",
      "epoch=073 train_loss=0.36237 val_loss=0.46648 val_accuracy=0.86600\n",
      "epoch=074 train_loss=0.46939 val_loss=0.46519 val_accuracy=0.86800\n",
      "epoch=075 train_loss=0.47389 val_loss=0.46397 val_accuracy=0.86800\n",
      "epoch=076 train_loss=0.40533 val_loss=0.46276 val_accuracy=0.86800\n",
      "epoch=077 train_loss=0.30749 val_loss=0.46169 val_accuracy=0.87000\n",
      "epoch=078 train_loss=0.36100 val_loss=0.46071 val_accuracy=0.87200\n",
      "epoch=079 train_loss=0.45433 val_loss=0.45977 val_accuracy=0.87200\n",
      "epoch=080 train_loss=0.37267 val_loss=0.45894 val_accuracy=0.87200\n",
      "epoch=081 train_loss=0.40830 val_loss=0.45820 val_accuracy=0.87200\n",
      "epoch=082 train_loss=0.37283 val_loss=0.45733 val_accuracy=0.87200\n",
      "epoch=083 train_loss=0.44264 val_loss=0.45601 val_accuracy=0.87200\n",
      "epoch=084 train_loss=0.45866 val_loss=0.45483 val_accuracy=0.87200\n",
      "epoch=085 train_loss=0.38687 val_loss=0.45396 val_accuracy=0.87200\n",
      "epoch=086 train_loss=0.41339 val_loss=0.45301 val_accuracy=0.87200\n",
      "epoch=087 train_loss=0.40454 val_loss=0.45219 val_accuracy=0.87400\n",
      "epoch=088 train_loss=0.40107 val_loss=0.45112 val_accuracy=0.87400\n",
      "epoch=089 train_loss=0.30251 val_loss=0.45069 val_accuracy=0.87400\n",
      "epoch=090 train_loss=0.36491 val_loss=0.44954 val_accuracy=0.87400\n",
      "epoch=091 train_loss=0.44221 val_loss=0.44887 val_accuracy=0.87600\n",
      "epoch=092 train_loss=0.43961 val_loss=0.44794 val_accuracy=0.87600\n",
      "epoch=093 train_loss=0.42754 val_loss=0.44729 val_accuracy=0.87600\n",
      "epoch=094 train_loss=0.41548 val_loss=0.44623 val_accuracy=0.87600\n",
      "epoch=095 train_loss=0.33747 val_loss=0.44557 val_accuracy=0.87600\n",
      "epoch=096 train_loss=0.30823 val_loss=0.44476 val_accuracy=0.87600\n",
      "epoch=097 train_loss=0.46299 val_loss=0.44390 val_accuracy=0.87600\n",
      "epoch=098 train_loss=0.34236 val_loss=0.44355 val_accuracy=0.87600\n",
      "epoch=099 train_loss=0.38334 val_loss=0.44280 val_accuracy=0.87600\n",
      "epoch=100 train_loss=0.40163 val_loss=0.44191 val_accuracy=0.87600\n",
      "epoch=101 train_loss=0.39464 val_loss=0.44133 val_accuracy=0.87600\n"
     ]
    }
   ],
   "source": [
    "reset_iter_state(train_iter)\n",
    "\n",
    "while train_iter.epoch < training_epochs:\n",
    "    train_batch = train_iter.next()\n",
    "    image_train, target_train = concat_examples(train_batch)\n",
    "    \n",
    "    # Calculate the prediction of the network\n",
    "    prediction_train = model(image_train)\n",
    "\n",
    "    # Calculate the loss with softmax_cross_entropy\n",
    "    loss = F.softmax_cross_entropy(prediction_train, target_train)\n",
    "\n",
    "    # Calculate the gradients in the network\n",
    "    model.cleargrads()\n",
    "    loss.backward()\n",
    "\n",
    "    # Update all the trainable paremters\n",
    "    optimiser.update()\n",
    "    # --------------------- until here ---------------------\n",
    "\n",
    "    # Check the validation accuracy of prediction after every epoch\n",
    "    if train_iter.is_new_epoch and (train_iter.epoch + 1) % display_step == 0:\n",
    "        # If this iteration is the final iteration of the current epoch\n",
    "\n",
    "        test_losses = []\n",
    "        test_accuracies = []\n",
    "        while True:\n",
    "            test_batch = test_iter.next()\n",
    "            image_test, target_test = concat_examples(test_batch)\n",
    "\n",
    "            # Forward the test data\n",
    "            prediction_test = model(image_test)\n",
    "\n",
    "            # Calculate the loss\n",
    "            loss_test = F.softmax_cross_entropy(prediction_test, target_test)\n",
    "            test_losses.append(loss_test.data)\n",
    "\n",
    "            # Calculate the accuracy\n",
    "            accuracy = F.accuracy(prediction_test, target_test)\n",
    "            test_accuracies.append(accuracy.data)\n",
    "\n",
    "            if test_iter.is_new_epoch:\n",
    "                reset_iter_state(test_iter)\n",
    "                break\n",
    "\n",
    "        print('epoch={:03d} train_loss={:.05f} val_loss={:.05f} val_accuracy={:.05f}'.format(\n",
    "            train_iter.epoch, float(loss.data), np.mean(test_losses), np.mean(test_accuracies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
